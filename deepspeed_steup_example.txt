How many different machines will you use (use more than 1 for multi-node training)? [1]: 1  

Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no   

Do you wish to optimize your script with torch dynamo?[yes/NO]:no    

Do you want to use DeepSpeed? [yes/NO]: yes                  

Do you want to specify a json file to a DeepSpeed config? [yes/NO]: yes

Please enter the path to the json DeepSpeed config file: 
/path/you/want/to/save/this/json/file.json

Do you want to enable deepspeed.zero.Init when using ZeRO Stage-3 for constructing massive models? [yes/NO]: no  

Do you want to enable Mixture-of-Experts training (MoE)? [yes/NO]: no

How many GPU(s) should be used for distributed training? [1]:1      

